"""
Excel Processor for Geometry V2 Mode
- Validates Excel columns based on UI dropdown selections
- Processes batch encoding with shape-specific data extraction
- Supports chunked processing for large files
"""

import pandas as pd
import os
import json
import gc
import warnings
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Callable

# Suppress pandas warnings
warnings.filterwarnings('ignore', category=FutureWarning)


class ExcelProcessor:
    def __init__(self, service):
        """
        Initialize Excel Processor

        Args:
            service: GeometryV2Service instance
        """
        self.service = service
        self.column_mapping = self._load_column_mapping()

        # Large file thresholds
        self.LARGE_FILE_SIZE_MB = 10
        self.LARGE_FILE_ROWS = 50000
        self.DEFAULT_CHUNK_SIZE = 1000

    def _load_column_mapping(self) -> Dict:
        """Load Excel column mapping config"""
        try:
            current_file = os.path.abspath(__file__)
            current_dir = os.path.dirname(current_file)
            parent_dir = os.path.dirname(current_dir)
            root_dir = os.path.dirname(parent_dir)

            config_path = os.path.join(
                root_dir, 'config', 'geometry_v2_mode', 'excel_column_mapping.json'
            )

            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                print(f"‚ö†Ô∏è Warning: Column mapping file not found: {config_path}")
                return {}
        except Exception as e:
            print(f"‚ö†Ô∏è Warning: Could not load column mapping: {e}")
            return {}

    # ========== FILE VALIDATION ==========

    def is_large_file(self, file_path: str) -> Tuple[bool, Dict]:
        """
        Ki·ªÉm tra file c√≥ ph·∫£i large file kh√¥ng

        Args:
            file_path: ƒê∆∞·ªùng d·∫´n file Excel

        Returns:
            Tuple[bool, Dict]: (is_large, file_info)
        """
        try:
            file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
            is_large = file_size_mb > self.LARGE_FILE_SIZE_MB

            file_info = {
                'size_mb': round(file_size_mb, 2),
                'is_large': is_large,
                'recommended_chunk_size': self.DEFAULT_CHUNK_SIZE if is_large else None
            }

            return is_large, file_info

        except Exception as e:
            return False, {'error': str(e)}

    def _get_shape_required_columns(self, shape: str, group: str) -> List[str]:
        """
        L·∫•y danh s√°ch columns c·∫ßn thi·∫øt cho 1 shape

        Args:
            shape: T√™n shape (ƒêi·ªÉm, Vecto, ƒê∆∞·ªùng th·∫≥ng, ...)
            group: 'a' ho·∫∑c 'b'

        Returns:
            List c√°c column names c·∫ßn c√≥ trong Excel
        """
        if not shape:
            return []

        mapping_key = f"group_{group}_mapping"
        shape_mapping = self.column_mapping.get(mapping_key, {}).get(shape, {})

        if not shape_mapping:
            print(f"‚ö†Ô∏è Warning: No mapping found for {group.upper()} - {shape}")
            return []

        return shape_mapping.get('required_columns', [])

    def _extract_shape_data_from_row(self, row: pd.Series, shape: str, group: str) -> Dict:
        """
        Extract data t·ª´ Excel row cho m·ªôt shape c·ª• th·ªÉ

        Args:
            row: Pandas Series (1 row)
            shape: Shape name (ƒêi·ªÉm, Vecto, ...)
            group: 'a' ho·∫∑c 'b'

        Returns:
            Dict data cho encoder
        """
        mapping_key = f"group_{group}_mapping"
        shape_mapping = self.column_mapping.get(mapping_key, {}).get(shape, {})

        if not shape_mapping:
            raise ValueError(f"No mapping found for {group.upper()} - {shape}")

        data = {}
        columns_config = shape_mapping.get('columns', {})

        for data_key, col_config in columns_config.items():
            excel_col = col_config['excel_column']

            if excel_col in row.index:
                value = row[excel_col]

                # Convert NaN to empty string
                if pd.isna(value):
                    value = ""
                else:
                    value = str(value).strip()

                # Check required
                if col_config.get('required', False) and not value:
                    raise ValueError(
                        f"Missing required value in '{excel_col}' for {shape}"
                    )

                data[data_key] = value
            elif col_config.get('required', False):
                raise ValueError(
                    f"Column '{excel_col}' not found (required for {shape})"
                )

        return data

    # ========== NORMAL FILE PROCESSING ==========

    def process_file(self, input_path: str, output_path: str,
                     progress_callback: Optional[Callable] = None,
                     operation: str = None,
                     shape_a: str = None,
                     shape_b: str = None,
                     dimension_a: str = "3",
                     dimension_b: str = "3",
                     version: str = "fx799") -> Dict:
        """
        X·ª≠ l√Ω Excel theo workflow:
        1. Validate columns d·ª±a tr√™n Shape A & B t·ª´ UI
        2. ƒê·ªçc Operation t·ª´ UI
        3. X·ª≠ l√Ω h√†ng lo·∫°t

        Args:
            input_path: File Excel input
            output_path: File Excel output
            progress_callback: Progress callback function
            operation: Ph√©p to√°n t·ª´ UI dropdown
            shape_a: Shape nh√≥m A t·ª´ UI dropdown
            shape_b: Shape nh√≥m B t·ª´ UI dropdown (None n·∫øu single-object)
            dimension_a: Dimension A (2D/3D)
            dimension_b: Dimension B (2D/3D)
            version: Casio version
        """
        try:
            # ========== 1. READ EXCEL ==========
            df = pd.read_excel(input_path)
            total_rows = len(df)

            print(f"\nüìä Processing {total_rows} rows...")
            print(f"üìã Excel columns: {list(df.columns)}")

            # ========== 2. VALIDATE REQUIRED PARAMS ==========
            if not operation or not shape_a:
                return {
                    'success': False,
                    'error': 'Vui l√≤ng ch·ªçn Ph√©p to√°n v√† Shape A t·ª´ UI dropdown!'
                }

            print(f"\nüìå Config t·ª´ UI:")
            print(f"   Operation: {operation}")
            print(f"   Shape A: {shape_a} ({dimension_a}D)")
            if shape_b:
                print(f"   Shape B: {shape_b} ({dimension_b}D)")

            # ========== 3. GET REQUIRED COLUMNS cho Shape A & B ==========
            required_columns_a = self._get_shape_required_columns(shape_a, 'a')
            required_columns_b = self._get_shape_required_columns(shape_b, 'b') if shape_b else []

            all_required_columns = required_columns_a + required_columns_b

            print(f"\nüîç Checking Excel columns...")
            print(f"   Shape A ({shape_a}) c·∫ßn: {required_columns_a}")
            if shape_b:
                print(f"   Shape B ({shape_b}) c·∫ßn: {required_columns_b}")

            # ========== 4. VALIDATE EXCEL HAS REQUIRED COLUMNS ==========
            excel_columns = set(df.columns)
            missing_columns = [col for col in all_required_columns if col not in excel_columns]

            if missing_columns:
                error_msg = (
                    f"‚ùå File Excel thi·∫øu c√°c c·ªôt c·∫ßn thi·∫øt!\n\n"
                    f"Dropdown hi·ªán t·∫°i:\n"
                    f"  ‚Ä¢ Shape A: {shape_a}\n"
                )
                if shape_b:
                    error_msg += f"  ‚Ä¢ Shape B: {shape_b}\n"

                error_msg += f"\nC√°c c·ªôt b·ªã thi·∫øu:\n"
                for col in missing_columns:
                    error_msg += f"  ‚ùå {col}\n"

                error_msg += f"\nC√°c c·ªôt c√≥ trong Excel:\n"
                for col in sorted(excel_columns):
                    error_msg += f"  ‚úì {col}\n"

                print(error_msg)
                return {'success': False, 'error': error_msg}

            print(f"   ‚úÖ T·∫•t c·∫£ columns c·∫ßn thi·∫øt ƒë·ªÅu c√≥!")

            # ========== 5. ENSURE KEYLOG COLUMN ==========
            if 'keylog' not in df.columns:
                df['keylog'] = pd.Series('', dtype='str', index=df.index)
                print("   ‚Üí Added 'keylog' column")
            else:
                df['keylog'] = df['keylog'].astype('str')
                print("   ‚Üí 'keylog' column exists, will overwrite")

            # ========== 6. CONFIGURE SERVICE ==========
            self.service.set_operation(operation)
            self.service.set_shapes(shape_a, shape_b)
            self.service.set_dimension(dimension_a, dimension_b)
            self.service.set_version(version)

            # ========== 7. PROCESS ROWS ==========
            processed = 0
            errors = 0

            print(f"\n‚öôÔ∏è Processing rows...\n")

            for idx, row in df.iterrows():
                try:
                    # Extract data cho Shape A
                    data_a = self._extract_shape_data_from_row(row, shape_a, 'a')

                    # Extract data cho Shape B (n·∫øu c√≥)
                    data_b = None
                    if shape_b:
                        data_b = self._extract_shape_data_from_row(row, shape_b, 'b')

                    # Encode
                    result = self.service.process_manual_data(data_a, data_b)

                    if result['success']:
                        df.loc[idx, 'keylog'] = str(result['encoded'])
                        processed += 1
                    else:
                        df.loc[idx, 'keylog'] = f"ERROR: {result.get('error', 'Unknown')}"
                        errors += 1

                    # Progress callback
                    if progress_callback and (idx + 1) % 100 == 0:
                        progress_callback(idx + 1, total_rows, errors)

                except Exception as e:
                    df.loc[idx, 'keylog'] = f"ERROR: {str(e)}"
                    errors += 1
                    if errors <= 5:
                        print(f"‚ö†Ô∏è Row {idx + 1}: {str(e)}")

            # ========== 8. SAVE OUTPUT ==========
            # Move keylog to end
            if 'keylog' in df.columns:
                cols = [c for c in df.columns if c != 'keylog'] + ['keylog']
                df = df[cols]

            df.to_excel(output_path, index=False)

            print(f"\n‚úÖ Processing complete!")
            print(f"   Success: {processed}/{total_rows}")
            print(f"   Errors: {errors}/{total_rows}")
            print(f"üìÅ Output: {output_path}")

            return {
                'success': True,
                'processed': processed,
                'errors': errors,
                'total': total_rows,
                'output_file': output_path
            }

        except Exception as e:
            return {'success': False, 'error': f'L·ªói x·ª≠ l√Ω file: {str(e)}'}

    # ========== LARGE FILE PROCESSING (CHUNKED) ==========

    def process_large_file(self, input_path: str, output_path: str,
                           chunk_size: int = 1000,
                           progress_callback: Optional[Callable] = None,
                           operation: str = None,
                           shape_a: str = None,
                           shape_b: str = None,
                           dimension_a: str = "3",
                           dimension_b: str = "3",
                           version: str = "fx799") -> Dict:
        """
        X·ª≠ l√Ω large file v·ªõi manual chunking (pandas read_excel kh√¥ng support chunksize)
        """
        try:
            print(f"üîÑ Large file processing: chunk_size={chunk_size}")

            # Validate params
            if not operation or not shape_a:
                return {
                    'success': False,
                    'error': 'Vui l√≤ng ch·ªçn Ph√©p to√°n v√† Shape A t·ª´ UI dropdown!'
                }

            # ‚úÖ READ ENTIRE FILE FIRST (c√≥ th·ªÉ t·ªën memory nh∆∞ng c·∫ßn thi·∫øt)
            print(f"üìñ Reading Excel file...")
            df = pd.read_excel(input_path)
            total_rows = len(df)

            print(f"üìä Total rows: {total_rows}")

            # Get required columns
            required_columns_a = self._get_shape_required_columns(shape_a, 'a')
            required_columns_b = self._get_shape_required_columns(shape_b, 'b') if shape_b else []
            all_required_columns = required_columns_a + required_columns_b

            # Validate columns
            excel_columns = set(df.columns)
            missing_columns = [col for col in all_required_columns if col not in excel_columns]

            if missing_columns:
                error_msg = (
                    f"‚ùå File Excel thi·∫øu c√°c c·ªôt:\n"
                    f"{', '.join(missing_columns)}\n\n"
                    f"C·∫ßn c√≥: {', '.join(all_required_columns)}"
                )
                return {'success': False, 'error': error_msg}

            print(f"\nüìå Config t·ª´ UI:")
            print(f"   Operation: {operation}")
            print(f"   Shape A: {shape_a} ({dimension_a}D)")
            if shape_b:
                print(f"   Shape B: {shape_b} ({dimension_b}D)")

            # Configure service once
            self.service.set_operation(operation)
            self.service.set_shapes(shape_a, shape_b)
            self.service.set_dimension(dimension_a, dimension_b)
            self.service.set_version(version)

            # Ensure keylog column
            if 'keylog' not in df.columns:
                df['keylog'] = pd.Series('', dtype='str', index=df.index)
            else:
                df['keylog'] = df['keylog'].astype('str')

            # ‚úÖ PROCESS IN CHUNKS MANUALLY
            processed = 0
            errors = 0
            num_chunks = (total_rows + chunk_size - 1) // chunk_size

            print(f"\n‚öôÔ∏è Processing {num_chunks} chunks...")

            for chunk_idx in range(num_chunks):
                start_idx = chunk_idx * chunk_size
                end_idx = min(start_idx + chunk_size, total_rows)

                print(f"üì¶ Chunk {chunk_idx + 1}/{num_chunks} (rows {start_idx}-{end_idx})")

                # Process rows in this chunk
                for idx in range(start_idx, end_idx):
                    try:
                        row = df.iloc[idx]

                        data_a = self._extract_shape_data_from_row(row, shape_a, 'a')
                        data_b = None
                        if shape_b:
                            data_b = self._extract_shape_data_from_row(row, shape_b, 'b')

                        result = self.service.process_manual_data(data_a, data_b)

                        if result['success']:
                            df.at[idx, 'keylog'] = str(result['encoded'])
                            processed += 1
                        else:
                            df.at[idx, 'keylog'] = f"ERROR: {result.get('error', 'Unknown')}"
                            errors += 1

                        if progress_callback and (idx + 1) % 100 == 0:
                            progress_callback(idx + 1, total_rows, errors)

                    except Exception as e:
                        df.at[idx, 'keylog'] = f"ERROR: {str(e)}"
                        errors += 1

                # Memory cleanup after each chunk
                gc.collect()

            # Move keylog to end
            if 'keylog' in df.columns:
                cols = [c for c in df.columns if c != 'keylog'] + ['keylog']
                df = df[cols]

            # ‚úÖ WRITE OUTPUT
            print(f"\nüíæ Writing output file...")
            df.to_excel(output_path, index=False)

            print(f"\n‚úÖ Large file processing complete!")
            print(f"   Total: {total_rows} | Success: {processed} | Errors: {errors}")

            return {
                'success': True,
                'processed': processed,
                'errors': errors,
                'total': total_rows,
                'output_file': output_path,
                'chunks_processed': num_chunks
            }

        except Exception as e:
            return {'success': False, 'error': f'L·ªói x·ª≠ l√Ω large file: {str(e)}'}

    def _get_total_rows(self, file_path: str) -> int:
        """Get total rows trong Excel file"""
        try:
            with pd.ExcelFile(file_path) as xls:
                sheet = xls.parse(xls.sheet_names[0])
                return len(sheet)
        except:
            return 0

    # ========== AUTO PROCESSOR (SMART SELECTION) ==========

    def process_file_auto(self, input_path: str, output_path: str,
                          progress_callback: Optional[Callable] = None,
                          operation: str = None,
                          shape_a: str = None,
                          shape_b: str = None,
                          dimension_a: str = "3",
                          dimension_b: str = "3",
                          version: str = "fx799") -> Dict:
        """
        T·ª± ƒë·ªông ch·ªçn processor ph√π h·ª£p (normal vs chunked)
        """
        is_large, file_info = self.is_large_file(input_path)

        if is_large:
            print(f"üìä Large file detected ({file_info['size_mb']} MB)")
            print(f"   Using chunked processing...")
            return self.process_large_file(
                input_path,
                output_path,
                chunk_size=file_info['recommended_chunk_size'],
                progress_callback=progress_callback,
                operation=operation,
                shape_a=shape_a,
                shape_b=shape_b,
                dimension_a=dimension_a,
                dimension_b=dimension_b,
                version=version
            )
        else:
            print(f"üìÑ Normal file ({file_info['size_mb']} MB)")
            print(f"   Using standard processing...")
            return self.process_file(
                input_path,
                output_path,
                progress_callback=progress_callback,
                operation=operation,
                shape_a=shape_a,
                shape_b=shape_b,
                dimension_a=dimension_a,
                dimension_b=dimension_b,
                version=version
            )
